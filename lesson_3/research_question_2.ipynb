{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastbook import *\n",
    "from fastai.vision.all import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_stacked_tensors(data_path, number):\n",
    "    \"\"\"\n",
    "    This function receives the path where the images are stored + the label\n",
    "    (which in this case happens to be a number) and returns a tensor of rank 3\n",
    "    and shape [number of images, 28, 28] where each pixel goes from 0 (white) to 1 (black).\n",
    "    \"\"\"\n",
    "    values = (path/'{}'.format(data_path)/'{}'.format(number)).ls().sorted()\n",
    "    tensors = [tensor(Image.open(o)) for o in values]\n",
    "    stacked_tensors = torch.stack(tensors).float()/255\n",
    "    \n",
    "    return stacked_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_labels(dataset_rows, data_path):\n",
    "    \"\"\"\n",
    "    This function receives the total number of rows in the dataset (i.e. the number of images)\n",
    "    and the path where the images are stored, and returns a tensor of rank 2 and shape [dataset_rows, numbers],\n",
    "    where every row is an image and every column is a label (a number from 0 to 9 in this case). So, for each\n",
    "    image it has a vector that is 1 at the number it corresponds, and 0 for the rest.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    start = 0\n",
    "    numbers = len((path/'{}'.format(data_path)).ls())\n",
    "    for number in range(numbers): \n",
    "        labels_column = tensor([0]*dataset_rows)\n",
    "        number_rows = len((path/'{}'.format(data_path)/'{}'.format(number)).ls().sorted())\n",
    "        if number != 9:\n",
    "            labels_column[start:number_rows] = 1\n",
    "            start = number_rows\n",
    "        else:\n",
    "            labels_column[start:] = 1\n",
    "            \n",
    "        labels.append(labels_column)\n",
    "        \n",
    "    labels_tensor = torch.stack(labels)\n",
    "    \n",
    "    return torch.transpose(labels_tensor, 0, 1).view(-1, numbers).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_dataloader(data_path, batch_size=32):\n",
    "    \"\"\"\n",
    "    Given a data path and an optional batch size, returns a DataLoader object composed by x, a tensor of\n",
    "    rank 2 with shape [dataset_size, 28*28] (28*28 consists of putting height and weight in the same dimension) and\n",
    "    x, a tensor of rank 2 with shape [dataset_size, 10], where the column of size 10 is the labels vector.\n",
    "    \"\"\"\n",
    "    x = torch.cat([obtain_stacked_tensors(data_path, number) for number in range(10)]).view(-1, 28*28)\n",
    "    y = obtain_labels(x.shape[0], data_path)\n",
    "    \n",
    "    dset = list(zip(x, y))\n",
    "    \n",
    "    return DataLoader(dset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_dataloaders(data_path, batch_size=32, validation_set=0.2):\n",
    "    \"\"\"\n",
    "    Given a data path and an optional batch size, returns a DataLoader object composed by x, a tensor of\n",
    "    rank 2 with shape [dataset_size, 28*28] (28*28 consists of putting height and weight in the same dimension) and\n",
    "    x, a tensor of rank 2 with shape [dataset_size, 10], where the column of size 10 is the labels vector.\n",
    "    \"\"\"\n",
    "    x = torch.cat([obtain_stacked_tensors(data_path, number) for number in range(10)]).view(-1, 28*28)\n",
    "    y = obtain_labels(x.shape[0], data_path)\n",
    "    \n",
    "    dset = list(zip(x, y))\n",
    "    random.shuffle(dset)\n",
    "    \n",
    "    valid_dl_size = int(round(len(dset)*validation_set, 0))\n",
    "    valid_dl = DataLoader(dset[:valid_dl_size], batch_size, shuffle=True)\n",
    "    \n",
    "    training_dl = DataLoader(dset[valid_dl_size:], batch_size, shuffle=True)\n",
    "    \n",
    "    return training_dl, valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0):\n",
    "    \"\"\"\n",
    "    Given the parameters size and std, returns a tensor that allows gradeint calculations\n",
    "    of the size and std indicated.\n",
    "    \"\"\"\n",
    "    return (torch.randn(size)*std).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear1(xb):\n",
    "    \"\"\"\n",
    "    Given a tensor xb, returns xb tensor multiplied by weights tensor + bias tensor\n",
    "    \"\"\"\n",
    "    return xb@weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_preds(preds):\n",
    "    \"\"\"\n",
    "    Given a tensor preds, returns a new tensor of the same shape of the input but where only the maximum value\n",
    "    of the input tensor is different from zero (being one), and returning the rest of values as zeros.\n",
    "    \"\"\"\n",
    "    return torch.where(preds == max(preds), 1, 0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_correct(pred, target):\n",
    "    \"\"\"\n",
    "    Given a prediction tensor and a target tensor, returns True if the prediction tensor has the same values as\n",
    "    the target tensor for every column.\n",
    "    \"\"\"\n",
    "    return (pred == target).sum().item() == target.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(preds, targets):\n",
    "    \"\"\"\n",
    "    Given a predictions tensor and a targets tensor, returns the accuracy of the predictions against the targets.\n",
    "    \"\"\"\n",
    "    cleaned_preds = torch.stack([obtain_preds(pred) for pred in preds])\n",
    "    return tensor([obtain_correct(cleaned_preds[item], targets[item]) for item in range(targets.shape[0])]).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(preds, targets):\n",
    "    \"\"\"\n",
    "    Given a predictions tensor and a targets tensor, returns the mean of the sigmoid function\n",
    "    of the predictions and returns 1-prediction for the cases where the target value == 1 and\n",
    "    the prediction for the cases where the target value == 0.\n",
    "    This is because we want to minimize the difference between 1 and the prediction when the target is one\n",
    "    and the difference between the prediction and zero when the target is 0.\n",
    "    \"\"\"\n",
    "    my_preds = preds.sigmoid()\n",
    "    return (torch.where(targets==1, 1-my_preds, my_preds)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "    \"\"\"\n",
    "    Given a independient variables tensor xb, a dependent variables tensor yb and a model,\n",
    "    calculates the predictions of xb given the model, the loss function between the predictions and the actual\n",
    "    values yb, and computes the backpropagation of the loss function for each parameter of the model, obtaining\n",
    "    their gradients.\n",
    "    \"\"\"\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dl, lr, params):\n",
    "    \"\"\"\n",
    "    Performs the training of the model for one epoch. Given a model, a DataLoader object, a learning rate\n",
    "    and a params tuple, calculates the gradient for those params and performs one step on them.\n",
    "    \"\"\"\n",
    "    for xb, yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model, dl):\n",
    "    \"\"\"\n",
    "    Given a model and a DataLoader object, obtains the accuracy of the model for that DataLoader.\n",
    "    \"\"\"\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb, yb in dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The problem with the function we used is that is does not stratify our dataset, and thus we will get\n",
    "an uneven representation of the full dataset in both our training and validation datasets.\n",
    "\"\"\"\n",
    "\n",
    "training_dl, valid_dl = obtain_dataloaders('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params((28*28, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = init_params((1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2775"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear1, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8857 \n",
      "0.8858 \n",
      "0.8859 \n",
      "0.886 \n",
      "0.886 \n"
     ]
    }
   ],
   "source": [
    "lr = 1.\n",
    "params = weights, bias\n",
    "for i in range(5):\n",
    "    train_epoch(linear1, training_dl, lr, params)\n",
    "    print('{} '.format(validate_epoch(linear1, valid_dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(training_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(\n",
    "    dls,\n",
    "#     nn.Linear(28*28, 10),\n",
    "    simple_net,\n",
    "    opt_func=SGD,\n",
    "    loss_func=mnist_loss,\n",
    "    metrics=batch_accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.215184</td>\n",
       "      <td>0.210140</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.111236</td>\n",
       "      <td>0.110689</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.073621</td>\n",
       "      <td>0.071684</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.054111</td>\n",
       "      <td>0.054692</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.046644</td>\n",
       "      <td>0.045836</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.039246</td>\n",
       "      <td>0.040582</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.037916</td>\n",
       "      <td>0.037161</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.033086</td>\n",
       "      <td>0.034784</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.031624</td>\n",
       "      <td>0.033048</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.031364</td>\n",
       "      <td>0.031731</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
